# 1. Imports essenciais
import streamlit as st
import os
import google.generativeai as genai
from dotenv import load_dotenv

# 2. ConfiguraÃ§Ã£o da PÃ¡gina (Aba do Navegador)
# Deve ser o primeiro comando Streamlit do seu script!
st.set_page_config(
    page_title="Chatbot com Google Gemini",  # TÃ­tulo que aparece na aba do navegador
    page_icon="ğŸ¤–",                          # Ãcone da aba do navegador
    layout="wide",                           # Layout amplo ou centralizado
    initial_sidebar_state="expanded"         # Sidebar expandida ou colapsada
)

# 3. Carregamento e VerificaÃ§Ã£o da API Key
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Verificar se a API Key estÃ¡ presente
if not GEMINI_API_KEY:
    st.error("ğŸ”‘ API Key nÃ£o encontrada. Verifique o arquivo .env.")
    st.stop()

# 4. ConfiguraÃ§Ã£o da API do Gemini
genai.configure(api_key=GEMINI_API_KEY)

# FunÃ§Ã£o para INICIALIZAR o modelo com configuraÃ§Ãµes especÃ­ficas
def init_gemini():
    """Inicializa e retorna o modelo GenerativeModel do Gemini."""
    generation_config = {
        "temperature": 0.7,
        "top_p": 0.8,
        "top_k": 40,
        "max_output_tokens": 2048,
    }
    
    model = genai.GenerativeModel(
        model_name="gemini-2.0-flash",
        generation_config=generation_config
    )
    return model

# FunÃ§Ã£o para gerar resposta do chatbot
def generate_response(model, prompt_history):
    """
    Gera uma resposta do modelo Gemini, com tratamento de erros.
    Usa o histÃ³rico para dar mais contexto ao modelo.
    
    Args:
        model: O modelo Gemini inicializado.
        prompt_history: O histÃ³rico da conversa.
    
    Returns:
        str: A resposta gerada pelo modelo ou uma mensagem de erro.
    """
    try:
        # Nota: A API do Gemini pode se beneficiar do histÃ³rico completo.
        # Por simplicidade aqui, usamos apenas o Ãºltimo prompt, mas o ideal
        # seria enviar o histÃ³rico formatado.
        latest_prompt = prompt_history[-1]['content']
        response = model.generate_content(latest_prompt)
        return response.text
    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

# --- Interface GrÃ¡fica (UI) ---

# ConfiguraÃ§Ã£o da sidebar
with st.sidebar:
    st.header("âš™ï¸ ConfiguraÃ§Ãµes")
    
    if st.button("ğŸ—‘ï¸ Limpar Conversa"):
        # Limpa o estado da sessÃ£o
        st.session_state.messages = []
        # ForÃ§a a re-execuÃ§Ã£o do script para atualizar a UI
        st.rerun()
    
    st.divider()
    st.subheader("ğŸ“Š EstatÃ­sticas")
    # Usa 'st.session_state.get' para evitar erros se a chave nÃ£o existir
    st.metric("Mensagens trocadas", len(st.session_state.get('messages', [])))


# Inicializar o modelo na sessÃ£o se ainda nÃ£o existir
if 'model' not in st.session_state:
    with st.spinner("ğŸ”„ Inicializando modelo Gemini..."):
        st.session_state.model = init_gemini()

# TÃ­tulo e descriÃ§Ã£o principal
st.title("ğŸ¤– Chatbot com Google Gemini")
st.write("Bem-vindo ao seu assistente virtual inteligente!")

# PersonalizaÃ§Ã£o com CSS (opcional)
st.markdown("""
<style>
    .main > div {
        padding-top: 2rem;
    }
</style>
""", unsafe_allow_html=True)


# ==============================================================================
# =================== LÃ“GICA DE CHAT CORRIGIDA ===================================
# ==============================================================================

# 1. Inicializa o histÃ³rico de mensagens na sessÃ£o se for a primeira execuÃ§Ã£o
if 'messages' not in st.session_state:
    st.session_state.messages = []
    # Adiciona uma mensagem de boas-vindas inicial do assistente
    st.session_state.messages.append({
        "role": "assistant",
        "content": """ğŸ‘‹ OlÃ¡! Eu sou seu assistente virtual powered by Google Gemini. 

Posso ajudar vocÃª com:
- â“ Responder perguntas gerais
- ğŸ’» Explicar conceitos de programaÃ§Ã£o
- ğŸ“ Criar e revisar textos
- ğŸ§® Resolver problemas matemÃ¡ticos
- ğŸ¨ Ideias criativas

Como posso ajudar vocÃª hoje?"""
    })

# 2. LÃ“GICA DE PROCESSAMENTO (SEMPRE ANTES DA EXIBIÃ‡ÃƒO)
# Captura a entrada do usuÃ¡rio a partir da caixa de texto
if prompt := st.chat_input("ğŸ’¬ Digite sua mensagem aqui..."):
    # Adiciona a mensagem do usuÃ¡rio ao histÃ³rico de estado
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Gera a resposta do assistente
    with st.spinner("ğŸ¤” Pensando..."):
        # Passa o histÃ³rico para a funÃ§Ã£o de geraÃ§Ã£o para dar contexto
        response = generate_response(st.session_state.model, st.session_state.messages)
        # Adiciona a resposta do assistente ao histÃ³rico de estado
        st.session_state.messages.append({"role": "assistant", "content": response})
        # ForÃ§a um rerun para exibir a nova mensagem imediatamente
        st.rerun()


# 3. LÃ“GICA DE EXIBIÃ‡ÃƒO (SEMPRE POR ÃšLTIMO)
# Exibe cada mensagem guardada no histÃ³rico de estado
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])